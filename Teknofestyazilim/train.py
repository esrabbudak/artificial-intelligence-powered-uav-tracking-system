# -*- coding: utf-8 -*-
"""teknofest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wQ3JGDg48Nnh_gjmTzLCgqmtRiEhPEEc

'''
datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1/255, validation_split=0.2)
# Training and validation dataset
train = datagen.flow_from_directory('./train', seed=123, subset='training')
val = datagen.flow_from_directory('./train', seed=123, subset='validation')

train_generator = train_datagen.flow_from_directory(
    directory=r"./train/",
    target_size=(224, 224),
    color_mode="rgb",
    batch_size=32,
    class_mode="categorical",
    shuffle=True,
    seed=42
)

valid_generator = valid_datagen.flow_from_directory(
    directory=r"./val/",
    target_size=(224, 224),
    color_mode="rgb",
    batch_size=32,
    class_mode="categorical",
    shuffle=True,
    seed=42
)

test_generator = test_datagen.flow_from_directory(
    directory=r"./test/",
    target_size=(224, 224),
    color_mode="rgb",
    batch_size=1,
    class_mode=None,
    shuffle=False,
    seed=42
)

STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size
STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size
model.fit_generator(generator=train_generator,
                    steps_per_epoch=STEP_SIZE_TRAIN,
                    validation_data=valid_generator,
                    validation_steps=STEP_SIZE_VALID,
                    epochs=10
)

model.evaluate_generator(generator=valid_generator,
steps=STEP_SIZE_VALID)

STEP_SIZE_TEST=test_generator.n//test_generator.batch_size
test_generator.reset()
pred=model.predict_generator(test_generator,
steps=STEP_SIZE_TEST,
verbose=1)

predicted_class_indices=np.argmax(pred,axis=1)

labels = (train_generator.class_indices)
labels = dict((v,k) for k,v in labels.items())
predictions = [labels[k] for k in predicted_class_indices]

filenames=test_generator.filenames
results=pd.DataFrame({"Filename":filenames,
                      "Predictions":predictions})
results.to_csv("results.csv",index=False)
'''
"""

#import numpy as np
#import pandas as pd

#import matplotlib.pyplot as plt
#from PIL import Image
import tensorflow as tf
import os
import PIL
from tensorflow import keras
from tensorflow.keras.applications import ResNet152V2
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense
from tensorflow.keras.models import Model
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout
from keras.preprocessing.image import ImageDataGenerator

os.chdir('/home/sbicer/Documents/Atlas Ãœni/teknofest/converted')


src_path_train = "./train/"
src_path_test = "./test/"


image_datagen = ImageDataGenerator(
        rescale=1 / 255.0,
        #rotation_range=20,
        #zoom_range=0.05,
        #width_shift_range=0.05,
        #height_shift_range=0.05,
        #shear_range=0.05,
        #horizontal_flip=True,
        #fill_mode="nearest",
        validation_split=0.20)

test_datagen = ImageDataGenerator(rescale=1 / 255.0)


batch_size = 16

train_generator = image_datagen.flow_from_directory(
    directory=src_path_train,
    target_size=(128, 128),
    color_mode="rgb",
    batch_size=batch_size,
    class_mode="categorical",
    subset='training',
    shuffle=True,
    seed=42
)

valid_generator = image_datagen.flow_from_directory(
    directory=src_path_train,
    target_size=(128, 128),
    color_mode="rgb",
    batch_size=batch_size,
    class_mode="categorical",
    subset='validation',
    shuffle=True,
    seed=42
)

test_generator = test_datagen.flow_from_directory(
    directory=src_path_test,
    target_size=(128, 128),
    color_mode="rgb",
    batch_size=1,
    class_mode=None,
    shuffle=False,
    seed=42
)

print(train_generator.class_indices)
print(valid_generator.class_indices)
print(test_generator.class_indices)

from keras.layers import Dropout # type: ignore

def prepare_model():
    model = Sequential()
    model.add(Conv2D(32,kernel_size=(3,3),activation='relu', input_shape=(128, 128, 3)))
    #model.add(Dropout(0.5))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(32,kernel_size=(3,3),activation='relu')) #,input_shape=(100, 100, 3)))
    #model.add(Dropout(0.5))
    #model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(16,kernel_size=(3,3),activation='relu'))#,input_shape=(100, 100, 3)))
    #model.add(Dropout(0.5))
    model.add(Conv2D(16,kernel_size=(3,3),activation='relu'))#,input_shape=(100, 100, 3)))
    #model.add(Dropout(0.5))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(8,kernel_size=(3,3),activation='relu'))#,input_shape=(100, 100, 3)))
    #model.add(Dropout(0.5))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.6))
    model.add(Dense(5, activation='softmax'))
    model.compile(loss="categorical_crossentropy",optimizer="adam",metrics=['accuracy'], run_eagerly=True)
    return model

model = prepare_model()

model.fit(train_generator,
                #validation_data = train_generator,
                #steps_per_epoch = train_generator.n//train_generator.batch_size,
                #validation_steps = valid_generator.n//valid_generator.batch_size,
                epochs=30)

predict=model.predict(test_generator)
# predict the class label
y_classes = predict.argmax(axis=-1)

model.save("../models/h5format/model_30.h5")

score = model.evaluate(valid_generator)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

predict=model.predict(test_generator)
# predict the class label
y_classes = predict.argmax(axis=-1)
print(y_classes)